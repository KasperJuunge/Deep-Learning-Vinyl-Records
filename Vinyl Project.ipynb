{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This notebook will not run because the dataset is to big to be uploaded on github. Please download this repository and follow the instructions in the README-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Dropout\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import inspect\n",
    "from pandas_ml import ConfusionMatrix\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING TRAINING FUNCTION\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, device, dataset_sizes, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # FOR PLOTTING LEARNING CURVE\n",
    "    epoch_axis = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]\n",
    "    log_train_loss = []\n",
    "    log_train_acc = []\n",
    "    log_val_loss = []\n",
    "    log_val_acc = []\n",
    "\n",
    "    #FOR PLOTTING CONF. MATRIX\n",
    "    preds_temp = []\n",
    "    labels_temp = []\n",
    "    preds_best = []\n",
    "    labels_best = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\nEpoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        count = 0\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    #loss = criterion(preds, labels) # For MSELoss()\n",
    "\n",
    "                    #print(outputs)\n",
    "                    #print(preds)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                #print(preds.cpu().numpy()[0])\n",
    "                #print(preds.cpu().numpy()[1])\n",
    "                # PREPARE CONF. MATRIX\n",
    "                for x in range(len(labels)):\n",
    "                    labels_temp.append(labels.cpu().numpy()[x])\n",
    "\n",
    "                for x in range(len(preds)):\n",
    "                    preds_temp.append(preds.cpu().numpy()[x])\n",
    "\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'train': # Saving training loss and acc for later plotting\n",
    "                log_train_loss.append(epoch_loss)\n",
    "                log_train_acc.append(epoch_acc)\n",
    "                #print(log_train_loss)\n",
    "                #print(log_train_acc)\n",
    "            \n",
    "            if phase == 'val': # Saving validation loss and acc for later plotting\n",
    "                log_val_loss.append(epoch_loss)\n",
    "                log_val_acc.append(epoch_acc)\n",
    "                #print(log_val_loss)\n",
    "                #print(log_val_acc)\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc: # deep copy the model + saving best preds and labels\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                preds_best = preds_temp\n",
    "                labels_best = labels_temp\n",
    "                \n",
    "\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "\n",
    "    # PREPARE TRAINING CURVE PLOT\n",
    "    # Define data to be plotted\n",
    "    print(\"\\nPlotting training curve..\")\n",
    "    df = pd.DataFrame({ \n",
    "    'epoch_axis': epoch_axis,\n",
    "    'val_acc': log_val_acc,\n",
    "    'val_loss': log_val_loss,\n",
    "    'train_acc': log_train_acc,\n",
    "    'train_loss': log_train_loss\n",
    "    })\n",
    "    \n",
    "    # multiple line plot\n",
    "    plt.plot( 'epoch_axis', 'val_acc', data=df, marker='' , color='blue', linewidth=1)\n",
    "    plt.plot( 'epoch_axis', 'val_loss', data=df, marker='', color='red', linewidth=1)\n",
    "    plt.plot( 'epoch_axis', 'train_acc', data=df, marker='' , color='blue', linewidth=1, linestyle='dashed')\n",
    "    plt.plot( 'epoch_axis', 'train_loss', data=df, marker='', color='red', linewidth=1, linestyle='dashed')\n",
    "    plt.legend(('Val. Acc.', 'Val. Loss', 'Train Acc.', 'Train Loss'))\n",
    "\n",
    "\n",
    "    # PREPARE CONFUSION MATRIX PLOT \n",
    "    print(\"\\nPlotting confusion matrix.\")\n",
    "    #confusion_matrix = ConfusionMatrix(labels_best, preds_best)\n",
    "    confusion_matrix = ConfusionMatrix(labels_best, preds_best, labels=['60s', '70s', '80s'])\n",
    "    confusion_matrix.plot(normalized=True)\n",
    "    print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n",
    "\n",
    "\n",
    "    # SAVE PREDS+LABELS BEST VECTORS\n",
    "    with open('LOGDATA_preds_best.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(preds_best, pickle_file)\n",
    "\n",
    "    with open('LOGDATA_labels_best.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(labels_best, pickle_file)\n",
    "\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE OTHER FUNCTIONS\n",
    "\n",
    "def define_data_transforms():\n",
    "\tdata_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.Grayscale(num_output_channels=1),        \n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "\t}  \n",
    "\treturn data_transforms\n",
    "\n",
    "\n",
    "def prepare_data(data_transforms, data_dir):\n",
    "\timage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\tdataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\tdataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\tclass_names = image_datasets['train'].classes\n",
    "\treturn (image_datasets, dataloaders, dataset_sizes, class_names)\n",
    "\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    print(\"\\nEntering visualize_model function\")\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d46e0007a015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# DATA PREP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/vinyl-dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# MAIN FILE\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "\n",
    "# DATA PREP\n",
    "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "data_dir = dir_path + '/vinyl-dataset'\n",
    "print(data_dir)\n",
    "data_transforms = define_data_transforms()\n",
    "(image_datasets, dataloaders, dataset_sizes, class_names) = prepare_data(data_transforms, data_dir)\n",
    "\n",
    "\n",
    "# USE GPU IF AVAILABLE\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# SHOW SOME IMGS\n",
    "#inputs, classes = next(iter(dataloaders['train'])) # Get a batch of training data\n",
    "#out = torchvision.utils.make_grid(inputs, nrow=4) # Make a grid from batch\n",
    "#imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "\n",
    "# LOAD PRETRAINED MODEL\n",
    "resnet18 = models.resnet18(pretrained=True) # Load pretrained resnet18 model\n",
    "#for param in resnet18.parameters(): # freeze all weights, except for last fc\n",
    "#    param.requires_grad = False\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 3)\n",
    "#resnet18.fc = nn.Sequential(nn.Linear(num_ftrs, 3)) # Add dropout to final fc layer\n",
    "resnet18 = resnet18.to(device) # Move model to GPU (or CPU, if you're GPU i whack!)\n",
    "\t\n",
    "\n",
    "# SET HYPERPARAMETERS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "# TRAINE THE MODEL\n",
    "resnet18 = train_model(resnet18, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, device, dataset_sizes,\n",
    "                       num_epochs=25)\n",
    "\n",
    "# SAVE MODEL\n",
    "print(\"\\nSaving model..\")\n",
    "torch.save(resnet18.state_dict(), \"/home/kasper/code/vinyl/LOGDATA_saved_model.pt\")\n",
    "\n",
    "\n",
    "#PLOT ALL PLOTS\n",
    "print(\"Plotting..\")\n",
    "plt.show(block=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
